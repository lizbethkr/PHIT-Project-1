{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Source\n",
    "The data used in this notebook is sourced from the National Centers for Environmental Information (NCEI): [Global Historical Climatology Network (GHCN) - Hourly](https://www.ncei.noaa.gov/products/global-historical-climatology-network-hourly). Refer to their documentation and terms of use.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Set\n",
    "\n",
    "Station_ID: the station identification code. The first two characters signify the FIPS country code, the third character is a network code identifying the station numbering system used, and the remaining eight characters contain the actual station ID.\n",
    "\n",
    "Station_Name: the name of the station.\n",
    "\n",
    "Year: the year the observation was taken in Coordinated Universal Time (UTC).\n",
    "\n",
    "Month: the month the observation was taken in Coordinated Universal Time (UTC).\n",
    "\n",
    "Day: the day the observation was taken in Coordinated Universal Time (UTC).\n",
    "\n",
    "Hour: the hour the observation was taken in Coordinated Universal Time (UTC).\n",
    "\n",
    "Latitude: latitude of the station (in decimal degrees). North (+); South (-).\n",
    "\n",
    "Longitude: the longitude of the station (in decimal degrees). East (+); West (-).\n",
    "\n",
    "Temperature: 2 meter (circa) Above Ground Level Air (dry bulb) Temperature (‚Å∞C to tenths)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes: \n",
    "- Raw data was removed in download_ghcn.py for storage purposes.\n",
    "- GHCN hourly dataset contained psv files for individual stations in specific years. When processing the data, it was converted to csv format files for all California stations in years 2003 - 2023.\n",
    "- Most columns were dropped as they were not needed. Columns kept were described above.\n",
    "- Duplicate rows were dropped."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # type: ignore\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Update paths to get source code from notebook_utils\n",
    "\n",
    "curr_dir = os.path.dirname(os.path.abspath('notebooks'))\n",
    "proj_dir = os.path.dirname(curr_dir)\n",
    "src_path = os.path.join(proj_dir, 'src')\n",
    "sys.path.append(src_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed file: reduced_CA_stations_2003.csv\n",
      "Processed file: reduced_CA_stations_2004.csv\n",
      "Processed file: reduced_CA_stations_2005.csv\n",
      "Processed file: reduced_CA_stations_2006.csv\n",
      "Processed file: reduced_CA_stations_2007.csv\n",
      "Processed file: reduced_CA_stations_2008.csv\n",
      "Processed file: reduced_CA_stations_2009.csv\n",
      "Processed file: reduced_CA_stations_2010.csv\n",
      "Processed file: reduced_CA_stations_2011.csv\n",
      "Processed file: reduced_CA_stations_2012.csv\n",
      "Processed file: reduced_CA_stations_2013.csv\n",
      "Processed file: reduced_CA_stations_2014.csv\n",
      "Processed file: reduced_CA_stations_2015.csv\n",
      "Processed file: reduced_CA_stations_2016.csv\n",
      "Processed file: reduced_CA_stations_2017.csv\n",
      "Processed file: reduced_CA_stations_2018.csv\n",
      "Processed file: reduced_CA_stations_2019.csv\n",
      "Processed file: reduced_CA_stations_2020.csv\n",
      "Processed file: reduced_CA_stations_2021.csv\n",
      "Processed file: reduced_CA_stations_2022.csv\n",
      "Processed file: reduced_CA_stations_2023.csv\n"
     ]
    }
   ],
   "source": [
    "from notebook_utils.preprocessing import combine_files_to_dfs\n",
    "\n",
    "# create a combined dataframe for all reduced csv files\n",
    "dfs = combine_files_to_dfs(\"../data/ghcn_reduced\")\n",
    "CA_stations = pd.concat(dfs, ignore_index=True) # type: ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Examination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Station_ID</th>\n",
       "      <th>Station_name</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>temperature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>USW00023225</td>\n",
       "      <td>BLUE CANYON NYACK AP</td>\n",
       "      <td>2003</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>39.2761</td>\n",
       "      <td>-120.7092</td>\n",
       "      <td>-1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>USW00023225</td>\n",
       "      <td>BLUE CANYON NYACK AP</td>\n",
       "      <td>2003</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>39.2761</td>\n",
       "      <td>-120.7092</td>\n",
       "      <td>-1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>USW00023225</td>\n",
       "      <td>BLUE CANYON NYACK AP</td>\n",
       "      <td>2003</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>39.2761</td>\n",
       "      <td>-120.7092</td>\n",
       "      <td>-1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>USW00023225</td>\n",
       "      <td>BLUE CANYON NYACK AP</td>\n",
       "      <td>2003</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>39.2761</td>\n",
       "      <td>-120.7092</td>\n",
       "      <td>-1.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>USW00023225</td>\n",
       "      <td>BLUE CANYON NYACK AP</td>\n",
       "      <td>2003</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>39.2761</td>\n",
       "      <td>-120.7092</td>\n",
       "      <td>-2.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Station_ID          Station_name  Year  Month  Day  Hour  Latitude  \\\n",
       "0  USW00023225  BLUE CANYON NYACK AP  2003      1    1     0   39.2761   \n",
       "1  USW00023225  BLUE CANYON NYACK AP  2003      1    1     1   39.2761   \n",
       "2  USW00023225  BLUE CANYON NYACK AP  2003      1    1     2   39.2761   \n",
       "3  USW00023225  BLUE CANYON NYACK AP  2003      1    1     3   39.2761   \n",
       "4  USW00023225  BLUE CANYON NYACK AP  2003      1    1     4   39.2761   \n",
       "\n",
       "   Longitude  temperature  \n",
       "0  -120.7092         -1.1  \n",
       "1  -120.7092         -1.1  \n",
       "2  -120.7092         -1.1  \n",
       "3  -120.7092         -1.7  \n",
       "4  -120.7092         -2.2  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CA_stations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 19851938 entries, 0 to 19851937\n",
      "Data columns (total 9 columns):\n",
      " #   Column        Dtype  \n",
      "---  ------        -----  \n",
      " 0   Station_ID    object \n",
      " 1   Station_name  object \n",
      " 2   Year          int64  \n",
      " 3   Month         int64  \n",
      " 4   Day           int64  \n",
      " 5   Hour          int64  \n",
      " 6   Latitude      float64\n",
      " 7   Longitude     float64\n",
      " 8   temperature   float64\n",
      "dtypes: float64(3), int64(4), object(2)\n",
      "memory usage: 1.3+ GB\n"
     ]
    }
   ],
   "source": [
    "CA_stations.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>temperature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.985194e+07</td>\n",
       "      <td>1.985194e+07</td>\n",
       "      <td>1.985194e+07</td>\n",
       "      <td>1.985194e+07</td>\n",
       "      <td>1.985194e+07</td>\n",
       "      <td>1.985194e+07</td>\n",
       "      <td>1.961237e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.013089e+03</td>\n",
       "      <td>6.504389e+00</td>\n",
       "      <td>1.573293e+01</td>\n",
       "      <td>1.159572e+01</td>\n",
       "      <td>3.668450e+01</td>\n",
       "      <td>-1.201430e+02</td>\n",
       "      <td>1.561475e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5.375401e+00</td>\n",
       "      <td>3.467041e+00</td>\n",
       "      <td>8.794091e+00</td>\n",
       "      <td>6.939050e+00</td>\n",
       "      <td>2.374357e+00</td>\n",
       "      <td>2.021136e+00</td>\n",
       "      <td>8.620436e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.003000e+03</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.256810e+01</td>\n",
       "      <td>-1.242381e+02</td>\n",
       "      <td>-9.900000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.009000e+03</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>8.000000e+00</td>\n",
       "      <td>6.000000e+00</td>\n",
       "      <td>3.441420e+01</td>\n",
       "      <td>-1.218150e+02</td>\n",
       "      <td>1.050000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.013000e+03</td>\n",
       "      <td>7.000000e+00</td>\n",
       "      <td>1.600000e+01</td>\n",
       "      <td>1.200000e+01</td>\n",
       "      <td>3.698500e+01</td>\n",
       "      <td>-1.204667e+02</td>\n",
       "      <td>1.470000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.018000e+03</td>\n",
       "      <td>1.000000e+01</td>\n",
       "      <td>2.300000e+01</td>\n",
       "      <td>1.800000e+01</td>\n",
       "      <td>3.832080e+01</td>\n",
       "      <td>-1.182911e+02</td>\n",
       "      <td>2.000000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.023000e+03</td>\n",
       "      <td>1.200000e+01</td>\n",
       "      <td>3.100000e+01</td>\n",
       "      <td>2.300000e+01</td>\n",
       "      <td>4.178360e+01</td>\n",
       "      <td>-1.161472e+02</td>\n",
       "      <td>9.020000e+02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Year         Month           Day          Hour      Latitude  \\\n",
       "count  1.985194e+07  1.985194e+07  1.985194e+07  1.985194e+07  1.985194e+07   \n",
       "mean   2.013089e+03  6.504389e+00  1.573293e+01  1.159572e+01  3.668450e+01   \n",
       "std    5.375401e+00  3.467041e+00  8.794091e+00  6.939050e+00  2.374357e+00   \n",
       "min    2.003000e+03  1.000000e+00  1.000000e+00  0.000000e+00  3.256810e+01   \n",
       "25%    2.009000e+03  3.000000e+00  8.000000e+00  6.000000e+00  3.441420e+01   \n",
       "50%    2.013000e+03  7.000000e+00  1.600000e+01  1.200000e+01  3.698500e+01   \n",
       "75%    2.018000e+03  1.000000e+01  2.300000e+01  1.800000e+01  3.832080e+01   \n",
       "max    2.023000e+03  1.200000e+01  3.100000e+01  2.300000e+01  4.178360e+01   \n",
       "\n",
       "          Longitude   temperature  \n",
       "count  1.985194e+07  1.961237e+07  \n",
       "mean  -1.201430e+02  1.561475e+01  \n",
       "std    2.021136e+00  8.620436e+00  \n",
       "min   -1.242381e+02 -9.900000e+01  \n",
       "25%   -1.218150e+02  1.050000e+01  \n",
       "50%   -1.204667e+02  1.470000e+01  \n",
       "75%   -1.182911e+02  2.000000e+01  \n",
       "max   -1.161472e+02  9.020000e+02  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CA_stations.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The temperature column has a really high max celsius value which is 902 degrees celsius. This is unreasonably high. After doing some searching, we found that the highest recorded temperature value was 56.7 degrees celsius in California 1913. \n",
    "\n",
    "There is also an unreasonably low temperature observation of -99 degrees celsius since the lowest recorded temperature observation on Earth was -98 degrees in Antartica. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Station_ID      False\n",
      "Station_name    False\n",
      "Year            False\n",
      "Month           False\n",
      "Day             False\n",
      "Hour            False\n",
      "Latitude        False\n",
      "Longitude       False\n",
      "temperature      True\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "# Checking which columns have missing data\n",
    "cols_missing_data = CA_stations.isnull().any()\n",
    "print(cols_missing_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While temperature is the only column with NA cells, there are some completely missing rows meaning not all hours from each year were observed. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning Invalid Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Handle Missing Values  (e.g., mean/median impuation, interpolation, forward or backward fill, k-nearest neighbors imputation, deletion)\n",
    "- Handle Outliers  (e.g., visual inspection by boxplots, Z-score and IQR method, or data transformation by log transformation and winsorization)\n",
    "- Handle inconsistencies (e.g., checking ranges to ensure temperature values fall within a reasonable range, unit consistency, string matching and standardization), and duplicates (identify and remove duplicates) in the dataset\n",
    "\n",
    "Notes:\n",
    "- For non-leap years, there should be 8760 rows (for each hour) for each station.\n",
    "- For leap years, there should be 8784 rows (for each hour) for each station\n",
    "- Leap years from 2003-2023 include: 2004, 2008, 2012, 2016, and 2020\n",
    "- The reduced files contain 99 CA stations.\n",
    "- Some stations are not observed each year from 2003-2023.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed file: reduced_CA_stations_2003.csv\n",
      "Processed file: reduced_CA_stations_2004.csv\n",
      "Processed file: reduced_CA_stations_2005.csv\n",
      "Processed file: reduced_CA_stations_2006.csv\n",
      "Processed file: reduced_CA_stations_2007.csv\n",
      "Processed file: reduced_CA_stations_2008.csv\n",
      "Processed file: reduced_CA_stations_2009.csv\n",
      "Processed file: reduced_CA_stations_2010.csv\n",
      "Processed file: reduced_CA_stations_2011.csv\n",
      "Processed file: reduced_CA_stations_2012.csv\n",
      "Processed file: reduced_CA_stations_2013.csv\n",
      "Processed file: reduced_CA_stations_2014.csv\n",
      "Processed file: reduced_CA_stations_2015.csv\n",
      "Processed file: reduced_CA_stations_2016.csv\n",
      "Processed file: reduced_CA_stations_2017.csv\n",
      "Processed file: reduced_CA_stations_2018.csv\n",
      "Processed file: reduced_CA_stations_2019.csv\n",
      "Processed file: reduced_CA_stations_2020.csv\n",
      "Processed file: reduced_CA_stations_2021.csv\n",
      "Processed file: reduced_CA_stations_2022.csv\n",
      "Processed file: reduced_CA_stations_2023.csv\n"
     ]
    }
   ],
   "source": [
    "# Create Individual Dataframes\n",
    "dataframes = combine_files_to_dfs(\"../data/ghcn_reduced\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filling missing rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Something"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filling missing temperature values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Missing Temperature Values: Handling short gaps in temperature observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a \"short gap\" as being a gap in the temperature column that is less than a day. \n",
    "\n",
    "Short gaps in temperature observations will be handled with forward/backward fill."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Missing Temperature Values: Handling large gaps in temperature observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a \"large gap\" as being a gap in the temperature column that is more than a day.\n",
    "\n",
    "Large gaps in temperature observations will be handled via interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Missing Values with Deletion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When there are more than _ % of missing temperature values in a station, it is removed from the data.\n",
    "\n",
    "When there are more than _% missing rows in a station, it is removed from the data.\n",
    "\n",
    "Note: Still\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Inconsistencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Ensure temperature observations are within -50¬∞C and 60¬∞C\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outliers can skew our statistical analysis of the data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Visual Inspection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Boxplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Statistical Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Z-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interquartile Range (IQR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Data Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Log Transformation or Winsorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
