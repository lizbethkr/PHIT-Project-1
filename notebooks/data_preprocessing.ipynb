{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Source\n",
    "The data used in this notebook is sourced from the National Centers for Environmental Information (NCEI): [Global Historical Climatology Network (GHCN) - Hourly](https://www.ncei.noaa.gov/products/global-historical-climatology-network-hourly). Refer to their documentation and terms of use.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Set\n",
    "\n",
    "Station_ID: the station identification code. The first two characters signify the FIPS country code, the third character is a network code identifying the station numbering system used, and the remaining eight characters contain the actual station ID.\n",
    "\n",
    "Station_Name: the name of the station.\n",
    "\n",
    "Year: the year the observation was taken in Coordinated Universal Time (UTC).\n",
    "\n",
    "Month: the month the observation was taken in Coordinated Universal Time (UTC).\n",
    "\n",
    "Day: the day the observation was taken in Coordinated Universal Time (UTC).\n",
    "\n",
    "Hour: the hour the observation was taken in Coordinated Universal Time (UTC).\n",
    "\n",
    "Latitude: latitude of the station (in decimal degrees). North (+); South (-).\n",
    "\n",
    "Longitude: the longitude of the station (in decimal degrees). East (+); West (-).\n",
    "\n",
    "Temperature: 2 meter (circa) Above Ground Level Air (dry bulb) Temperature (‚Å∞C to tenths)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes: \n",
    "- Raw data was removed in download_ghcn.py for storage purposes.\n",
    "- GHCN hourly dataset contained psv files for individual stations in specific years. When processing the data, it was converted to csv format files for all California stations in years 2003 - 2023.\n",
    "- Most columns were dropped as they were not needed. Columns kept were described above.\n",
    "- Duplicate rows that had completely same column values were dropped."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed file: full_CA_stations_2003.csv\n",
      "Processed file: full_CA_stations_2004.csv\n",
      "Processed file: full_CA_stations_2005.csv\n",
      "Processed file: full_CA_stations_2006.csv\n",
      "Processed file: full_CA_stations_2007.csv\n",
      "Processed file: full_CA_stations_2008.csv\n",
      "Processed file: full_CA_stations_2009.csv\n",
      "Processed file: full_CA_stations_2010.csv\n",
      "Processed file: full_CA_stations_2011.csv\n",
      "Processed file: full_CA_stations_2012.csv\n",
      "Processed file: full_CA_stations_2013.csv\n",
      "Processed file: full_CA_stations_2014.csv\n",
      "Processed file: full_CA_stations_2015.csv\n",
      "Processed file: full_CA_stations_2016.csv\n",
      "Processed file: full_CA_stations_2017.csv\n",
      "Processed file: full_CA_stations_2018.csv\n",
      "Processed file: full_CA_stations_2019.csv\n",
      "Processed file: full_CA_stations_2020.csv\n",
      "Processed file: full_CA_stations_2021.csv\n",
      "Processed file: full_CA_stations_2022.csv\n",
      "Processed file: full_CA_stations_2023.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd # type: ignore\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Update paths to get source code from notebook_utils\n",
    "curr_dir = os.path.dirname(os.path.abspath('notebooks'))\n",
    "proj_dir = os.path.dirname(curr_dir)\n",
    "src_path = os.path.join(proj_dir, 'src')\n",
    "sys.path.append(src_path)\n",
    "\n",
    "from notebook_utils.preprocessing import *\n",
    "\n",
    "CA_stations = get_full_df('../data/processed/ghcn_full', chunksize=500000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Examination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Station_ID</th>\n",
       "      <th>Station_name</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>temperature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GPW00000401</td>\n",
       "      <td>POINTE A PITRE INTL AP</td>\n",
       "      <td>2003</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>16.2669</td>\n",
       "      <td>-61.6</td>\n",
       "      <td>24.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GPW00000401</td>\n",
       "      <td>POINTE A PITRE INTL AP</td>\n",
       "      <td>2003</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16.2669</td>\n",
       "      <td>-61.6</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GPW00000401</td>\n",
       "      <td>POINTE A PITRE INTL AP</td>\n",
       "      <td>2003</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>16.2669</td>\n",
       "      <td>-61.6</td>\n",
       "      <td>24.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GPW00000401</td>\n",
       "      <td>POINTE A PITRE INTL AP</td>\n",
       "      <td>2003</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>16.2669</td>\n",
       "      <td>-61.6</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GPW00000401</td>\n",
       "      <td>POINTE A PITRE INTL AP</td>\n",
       "      <td>2003</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>16.2669</td>\n",
       "      <td>-61.6</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Station_ID            Station_name  Year  Month  Day  Hour  Latitude  \\\n",
       "0  GPW00000401  POINTE A PITRE INTL AP  2003      1    1     0   16.2669   \n",
       "1  GPW00000401  POINTE A PITRE INTL AP  2003      1    1     1   16.2669   \n",
       "2  GPW00000401  POINTE A PITRE INTL AP  2003      1    1     3   16.2669   \n",
       "3  GPW00000401  POINTE A PITRE INTL AP  2003      1    1     4   16.2669   \n",
       "4  GPW00000401  POINTE A PITRE INTL AP  2003      1    1     5   16.2669   \n",
       "\n",
       "   Longitude  temperature  \n",
       "0      -61.6         24.7  \n",
       "1      -61.6         25.0  \n",
       "2      -61.6         24.2  \n",
       "3      -61.6         24.0  \n",
       "4      -61.6         22.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CA_stations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 58090845 entries, 0 to 58090844\n",
      "Data columns (total 9 columns):\n",
      " #   Column        Dtype  \n",
      "---  ------        -----  \n",
      " 0   Station_ID    object \n",
      " 1   Station_name  object \n",
      " 2   Year          int64  \n",
      " 3   Month         int64  \n",
      " 4   Day           int64  \n",
      " 5   Hour          int64  \n",
      " 6   Latitude      float64\n",
      " 7   Longitude     float64\n",
      " 8   temperature   float64\n",
      "dtypes: float64(3), int64(4), object(2)\n",
      "memory usage: 3.9+ GB\n"
     ]
    }
   ],
   "source": [
    "CA_stations.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>temperature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.809084e+07</td>\n",
       "      <td>5.809084e+07</td>\n",
       "      <td>5.809084e+07</td>\n",
       "      <td>5.809084e+07</td>\n",
       "      <td>5.809084e+07</td>\n",
       "      <td>5.809084e+07</td>\n",
       "      <td>3.939865e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.013291e+03</td>\n",
       "      <td>6.504075e+00</td>\n",
       "      <td>1.573479e+01</td>\n",
       "      <td>1.155804e+01</td>\n",
       "      <td>3.617811e+01</td>\n",
       "      <td>-1.177964e+02</td>\n",
       "      <td>1.642611e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5.475781e+00</td>\n",
       "      <td>3.448708e+00</td>\n",
       "      <td>8.791612e+00</td>\n",
       "      <td>6.933797e+00</td>\n",
       "      <td>4.853230e+00</td>\n",
       "      <td>1.586318e+01</td>\n",
       "      <td>8.636838e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.003000e+03</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.115000e+01</td>\n",
       "      <td>-1.242390e+02</td>\n",
       "      <td>-9.900000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.009000e+03</td>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>8.000000e+00</td>\n",
       "      <td>6.000000e+00</td>\n",
       "      <td>3.440800e+01</td>\n",
       "      <td>-1.219586e+02</td>\n",
       "      <td>1.100000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.014000e+03</td>\n",
       "      <td>7.000000e+00</td>\n",
       "      <td>1.600000e+01</td>\n",
       "      <td>1.200000e+01</td>\n",
       "      <td>3.723810e+01</td>\n",
       "      <td>-1.205438e+02</td>\n",
       "      <td>1.560000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.018000e+03</td>\n",
       "      <td>1.000000e+01</td>\n",
       "      <td>2.300000e+01</td>\n",
       "      <td>1.800000e+01</td>\n",
       "      <td>3.885470e+01</td>\n",
       "      <td>-1.181500e+02</td>\n",
       "      <td>2.170000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.023000e+03</td>\n",
       "      <td>1.200000e+01</td>\n",
       "      <td>3.100000e+01</td>\n",
       "      <td>2.300000e+01</td>\n",
       "      <td>4.198800e+01</td>\n",
       "      <td>1.457700e+02</td>\n",
       "      <td>9.990000e+02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Year         Month           Day          Hour      Latitude  \\\n",
       "count  5.809084e+07  5.809084e+07  5.809084e+07  5.809084e+07  5.809084e+07   \n",
       "mean   2.013291e+03  6.504075e+00  1.573479e+01  1.155804e+01  3.617811e+01   \n",
       "std    5.475781e+00  3.448708e+00  8.791612e+00  6.933797e+00  4.853230e+00   \n",
       "min    2.003000e+03  1.000000e+00  1.000000e+00  0.000000e+00  1.115000e+01   \n",
       "25%    2.009000e+03  4.000000e+00  8.000000e+00  6.000000e+00  3.440800e+01   \n",
       "50%    2.014000e+03  7.000000e+00  1.600000e+01  1.200000e+01  3.723810e+01   \n",
       "75%    2.018000e+03  1.000000e+01  2.300000e+01  1.800000e+01  3.885470e+01   \n",
       "max    2.023000e+03  1.200000e+01  3.100000e+01  2.300000e+01  4.198800e+01   \n",
       "\n",
       "          Longitude   temperature  \n",
       "count  5.809084e+07  3.939865e+07  \n",
       "mean  -1.177964e+02  1.642611e+01  \n",
       "std    1.586318e+01  8.636838e+00  \n",
       "min   -1.242390e+02 -9.900000e+01  \n",
       "25%   -1.219586e+02  1.100000e+01  \n",
       "50%   -1.205438e+02  1.560000e+01  \n",
       "75%   -1.181500e+02  2.170000e+01  \n",
       "max    1.457700e+02  9.990000e+02  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CA_stations.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The temperature column has a really high max celsius value which is 902 degrees celsius. This is unreasonably high. After doing some searching, we found that the highest recorded temperature value was 56.7 degrees celsius in California 1913. \n",
    "\n",
    "There is also an unreasonably low temperature observation of -99 degrees celsius since the lowest recorded temperature observation on Earth was -98 degrees in Antartica. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 58090845 entries, 0 to 58090844\n",
      "Data columns (total 9 columns):\n",
      " #   Column        Dtype  \n",
      "---  ------        -----  \n",
      " 0   Station_ID    object \n",
      " 1   Station_name  object \n",
      " 2   Year          int16  \n",
      " 3   Month         int8   \n",
      " 4   Day           int8   \n",
      " 5   Hour          int8   \n",
      " 6   Latitude      float32\n",
      " 7   Longitude     float32\n",
      " 8   temperature   float32\n",
      "dtypes: float32(3), int16(1), int8(3), object(2)\n",
      "memory usage: 1.8+ GB\n"
     ]
    }
   ],
   "source": [
    "optimize_col_types(CA_stations)\n",
    "CA_stations.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning Invalid Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Handle Missing Values  (e.g., mean/median impuation, interpolation, forward or backward fill, k-nearest neighbors imputation, deletion)\n",
    "- Handle Outliers  (e.g., visual inspection by boxplots, Z-score and IQR method, or data transformation by log transformation and winsorization)\n",
    "- Handle inconsistencies (e.g., checking ranges to ensure temperature values fall within a reasonable range, unit consistency, string matching and standardization), and duplicates (identify and remove duplicates) in the dataset\n",
    "\n",
    "Notes:\n",
    "- For non-leap years, there should be 8760 rows (for each hour) for each station.\n",
    "- For leap years, there should be 8784 rows (for each hour) for each station\n",
    "- Leap years from 2003-2023 include: 2004, 2008, 2012, 2016, and 2020\n",
    "- The reduced files contain 99 CA stations.\n",
    "- Some stations are not observed each year from 2003-2023.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Inconsistencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Ensure temperature observations are within -50¬∞C and 60¬∞C\n",
    "2. Temperature values above the reasonable range will be converted to NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Station_ID</th>\n",
       "      <th>Station_name</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>temperature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4664225</th>\n",
       "      <td>USW00003154</td>\n",
       "      <td>CAMP PENDLETON MCAS</td>\n",
       "      <td>2005</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>33.304199</td>\n",
       "      <td>-117.355003</td>\n",
       "      <td>-89.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4665844</th>\n",
       "      <td>USW00003154</td>\n",
       "      <td>CAMP PENDLETON MCAS</td>\n",
       "      <td>2005</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>22</td>\n",
       "      <td>33.304199</td>\n",
       "      <td>-117.355003</td>\n",
       "      <td>-78.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4666040</th>\n",
       "      <td>USW00003154</td>\n",
       "      <td>CAMP PENDLETON MCAS</td>\n",
       "      <td>2005</td>\n",
       "      <td>11</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>33.304199</td>\n",
       "      <td>-117.355003</td>\n",
       "      <td>89.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4803671</th>\n",
       "      <td>USW00023110</td>\n",
       "      <td>LEMOORE REEVES NAS</td>\n",
       "      <td>2005</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>36.333302</td>\n",
       "      <td>-119.949997</td>\n",
       "      <td>94.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4803740</th>\n",
       "      <td>USW00023110</td>\n",
       "      <td>LEMOORE REEVES NAS</td>\n",
       "      <td>2005</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>36.333302</td>\n",
       "      <td>-119.949997</td>\n",
       "      <td>83.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57892973</th>\n",
       "      <td>USW00023289</td>\n",
       "      <td>PALO ALTO</td>\n",
       "      <td>2023</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>17</td>\n",
       "      <td>37.466702</td>\n",
       "      <td>-122.116699</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58011331</th>\n",
       "      <td>USW00093193</td>\n",
       "      <td>FRESNO YOSEMITE INTL</td>\n",
       "      <td>2023</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>36.779999</td>\n",
       "      <td>-119.720299</td>\n",
       "      <td>227.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58020400</th>\n",
       "      <td>USW00093201</td>\n",
       "      <td>TRUCKEE AP</td>\n",
       "      <td>2023</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "      <td>15</td>\n",
       "      <td>39.320000</td>\n",
       "      <td>-120.139397</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58067942</th>\n",
       "      <td>USW00093231</td>\n",
       "      <td>SAN CARLOS AP</td>\n",
       "      <td>2023</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>37.516701</td>\n",
       "      <td>-122.250000</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58068002</th>\n",
       "      <td>USW00093231</td>\n",
       "      <td>SAN CARLOS AP</td>\n",
       "      <td>2023</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>20</td>\n",
       "      <td>37.516701</td>\n",
       "      <td>-122.250000</td>\n",
       "      <td>170.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4491 rows √ó 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Station_ID          Station_name  Year  Month  Day  Hour  \\\n",
       "4664225   USW00003154   CAMP PENDLETON MCAS  2005     10   10     0   \n",
       "4665844   USW00003154   CAMP PENDLETON MCAS  2005     11   14    22   \n",
       "4666040   USW00003154   CAMP PENDLETON MCAS  2005     11   19     3   \n",
       "4803671   USW00023110    LEMOORE REEVES NAS  2005      2    7     3   \n",
       "4803740   USW00023110    LEMOORE REEVES NAS  2005      2    9     5   \n",
       "...               ...                   ...   ...    ...  ...   ...   \n",
       "57892973  USW00023289             PALO ALTO  2023      2    8    17   \n",
       "58011331  USW00093193  FRESNO YOSEMITE INTL  2023      5   15    16   \n",
       "58020400  USW00093201            TRUCKEE AP  2023      5   23    15   \n",
       "58067942  USW00093231         SAN CARLOS AP  2023      2   10    15   \n",
       "58068002  USW00093231         SAN CARLOS AP  2023      2   12    20   \n",
       "\n",
       "           Latitude   Longitude  temperature  \n",
       "4664225   33.304199 -117.355003        -89.0  \n",
       "4665844   33.304199 -117.355003        -78.0  \n",
       "4666040   33.304199 -117.355003         89.0  \n",
       "4803671   36.333302 -119.949997         94.0  \n",
       "4803740   36.333302 -119.949997         83.0  \n",
       "...             ...         ...          ...  \n",
       "57892973  37.466702 -122.116699         80.0  \n",
       "58011331  36.779999 -119.720299        227.0  \n",
       "58020400  39.320000 -120.139397         70.0  \n",
       "58067942  37.516701 -122.250000         70.0  \n",
       "58068002  37.516701 -122.250000        170.0  \n",
       "\n",
       "[4491 rows x 9 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check how many rows are below -50 and above 60 degrees celsius\n",
    "CA_stations[(CA_stations['temperature'] < -50) | (CA_stations['temperature'] > 60)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write code to turn temperature outside of the specified range into NaN\n",
    "CA_stations.loc[(CA_stations['temperature'] < -50) | (CA_stations['temperature'] > 60), 'temperature'] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deleting Duplicate Rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are rows with the same value in each column except temperature. In these cases we will average out the temperature observations and delete the extra rows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df = CA_stations.groupby(['Station_ID', 'Station_name', 'Year', 'Month', 'Day', 'Hour', 'Latitude', 'Longitude']).agg({'temperature': 'mean'}).reset_index()\n",
    "CA_stations = grouped_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filling missing rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391\n"
     ]
    }
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391\n"
     ]
    }
   ],
   "source": [
    "# create a reference dataframe with all stations with hours from 2003 to 2023\n",
    "full_df = create_full_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>temperature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>69967104</td>\n",
       "      <td>6.996710e+07</td>\n",
       "      <td>6.996710e+07</td>\n",
       "      <td>6.996710e+07</td>\n",
       "      <td>6.996710e+07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2013-03-16 23:30:00.000071680</td>\n",
       "      <td>2.012712e+03</td>\n",
       "      <td>6.451851e+00</td>\n",
       "      <td>1.572747e+01</td>\n",
       "      <td>1.150000e+01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2003-01-01 00:00:00</td>\n",
       "      <td>2.003000e+03</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2008-02-07 23:45:00</td>\n",
       "      <td>2.008000e+03</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>8.000000e+00</td>\n",
       "      <td>5.750000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2013-03-16 23:30:00</td>\n",
       "      <td>2.013000e+03</td>\n",
       "      <td>6.000000e+00</td>\n",
       "      <td>1.600000e+01</td>\n",
       "      <td>1.150000e+01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2018-04-23 23:15:00</td>\n",
       "      <td>2.018000e+03</td>\n",
       "      <td>9.000000e+00</td>\n",
       "      <td>2.300000e+01</td>\n",
       "      <td>1.725000e+01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2023-05-31 23:00:00</td>\n",
       "      <td>2.023000e+03</td>\n",
       "      <td>1.200000e+01</td>\n",
       "      <td>3.100000e+01</td>\n",
       "      <td>2.300000e+01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>5.896072e+00</td>\n",
       "      <td>3.455160e+00</td>\n",
       "      <td>8.799113e+00</td>\n",
       "      <td>6.922187e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            datetime          Year         Month  \\\n",
       "count                       69967104  6.996710e+07  6.996710e+07   \n",
       "mean   2013-03-16 23:30:00.000071680  2.012712e+03  6.451851e+00   \n",
       "min              2003-01-01 00:00:00  2.003000e+03  1.000000e+00   \n",
       "25%              2008-02-07 23:45:00  2.008000e+03  3.000000e+00   \n",
       "50%              2013-03-16 23:30:00  2.013000e+03  6.000000e+00   \n",
       "75%              2018-04-23 23:15:00  2.018000e+03  9.000000e+00   \n",
       "max              2023-05-31 23:00:00  2.023000e+03  1.200000e+01   \n",
       "std                              NaN  5.896072e+00  3.455160e+00   \n",
       "\n",
       "                Day          Hour  Latitude  Longitude  temperature  \n",
       "count  6.996710e+07  6.996710e+07       0.0        0.0          0.0  \n",
       "mean   1.572747e+01  1.150000e+01       NaN        NaN          NaN  \n",
       "min    1.000000e+00  0.000000e+00       NaN        NaN          NaN  \n",
       "25%    8.000000e+00  5.750000e+00       NaN        NaN          NaN  \n",
       "50%    1.600000e+01  1.150000e+01       NaN        NaN          NaN  \n",
       "75%    2.300000e+01  1.725000e+01       NaN        NaN          NaN  \n",
       "max    3.100000e+01  2.300000e+01       NaN        NaN          NaN  \n",
       "std    8.799113e+00  6.922187e+00       NaN        NaN          NaN  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in completely missing rows\n",
    "missing_rows = find_missing_rows(full_df, CA_stations)\n",
    "CA_stations = add_missing_rows(CA_stations, missing_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Station_ID  Year  Row_Count  Expected_Row_Count\n",
      "20    BBW00000408  2023       3628                3924\n",
      "41    CQL000LLBP7  2023       3624                3924\n",
      "62    DOW00000402  2023       3624                3924\n",
      "83    DOW00000403  2023       3624                3924\n",
      "104   GPW00000401  2023       3624                3924\n",
      "...           ...   ...        ...                 ...\n",
      "8126  USW00093242  2023       3624                3924\n",
      "8147  USW00093243  2023       3624                3924\n",
      "8168  USW00093244  2023       3624                3924\n",
      "8189  USW00093245  2023       3624                3924\n",
      "8210  USW00094299  2023       3624                3924\n",
      "\n",
      "[391 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "error = check_station_rows(CA_stations)\n",
    "print(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Station_ID</th>\n",
       "      <th>Station_name</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>temperature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45142748</th>\n",
       "      <td>USW00094299</td>\n",
       "      <td>ALTURAS MUNI AP</td>\n",
       "      <td>2023</td>\n",
       "      <td>5</td>\n",
       "      <td>31</td>\n",
       "      <td>19</td>\n",
       "      <td>41.483601</td>\n",
       "      <td>-120.561401</td>\n",
       "      <td>18.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45142749</th>\n",
       "      <td>USW00094299</td>\n",
       "      <td>ALTURAS MUNI AP</td>\n",
       "      <td>2023</td>\n",
       "      <td>5</td>\n",
       "      <td>31</td>\n",
       "      <td>20</td>\n",
       "      <td>41.483601</td>\n",
       "      <td>-120.561401</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45142750</th>\n",
       "      <td>USW00094299</td>\n",
       "      <td>ALTURAS MUNI AP</td>\n",
       "      <td>2023</td>\n",
       "      <td>5</td>\n",
       "      <td>31</td>\n",
       "      <td>21</td>\n",
       "      <td>41.483601</td>\n",
       "      <td>-120.561401</td>\n",
       "      <td>21.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69967135</th>\n",
       "      <td>USW00094299</td>\n",
       "      <td>ALTURAS MUNI AP</td>\n",
       "      <td>2023</td>\n",
       "      <td>5</td>\n",
       "      <td>31</td>\n",
       "      <td>22</td>\n",
       "      <td>41.483601</td>\n",
       "      <td>-120.561401</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69967136</th>\n",
       "      <td>USW00094299</td>\n",
       "      <td>ALTURAS MUNI AP</td>\n",
       "      <td>2023</td>\n",
       "      <td>5</td>\n",
       "      <td>31</td>\n",
       "      <td>23</td>\n",
       "      <td>41.483601</td>\n",
       "      <td>-120.561401</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Station_ID     Station_name  Year  Month  Day  Hour   Latitude  \\\n",
       "45142748  USW00094299  ALTURAS MUNI AP  2023      5   31    19  41.483601   \n",
       "45142749  USW00094299  ALTURAS MUNI AP  2023      5   31    20  41.483601   \n",
       "45142750  USW00094299  ALTURAS MUNI AP  2023      5   31    21  41.483601   \n",
       "69967135  USW00094299  ALTURAS MUNI AP  2023      5   31    22  41.483601   \n",
       "69967136  USW00094299  ALTURAS MUNI AP  2023      5   31    23  41.483601   \n",
       "\n",
       "           Longitude  temperature  \n",
       "45142748 -120.561401         18.9  \n",
       "45142749 -120.561401         20.0  \n",
       "45142750 -120.561401         21.1  \n",
       "69967135 -120.561401          NaN  \n",
       "69967136 -120.561401          NaN  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CA_stations.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Station Deletion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filling missing temperature values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stations with no Station_name values will be dropped as that means there are no observations recorded for them at all from 2003 - 2023\n",
    "- This is because the above Station_name for missing rows were filled in by using the Station_name used from a filled column with the same Station_ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "CA_stations.dropna(subset=['Station_name'], inplace=True) #353 stations left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of null values for each column: \n",
      "Station_ID       0.00000\n",
      "Station_name     0.00000\n",
      "Year             0.00000\n",
      "Month            0.00000\n",
      "Day              0.00000\n",
      "Hour             0.00000\n",
      "Latitude         0.00000\n",
      "Longitude        0.00000\n",
      "temperature     57.91542\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "null_count = CA_stations.isna().sum()\n",
    "null_percent = (null_count/CA_stations.shape[0]) * 100\n",
    "print(f'Percentage of null values for each column: \\n{null_percent}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing Temperature Values: Handling large gaps in temperature observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a \"large gap\" as being a gap in the temperature column that is more than a day.\n",
    "\n",
    "Large gaps in temperature observations will be handled via interpolation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cubic Spline Interpolation for large gaps of missing temperature values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reindex on an axis with duplicate labels",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[39], line 41\u001b[0m\n\u001b[0;32m     37\u001b[0m     data\u001b[38;5;241m.\u001b[39msort_values(by\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStation_ID\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYear\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMonth\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDay\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHour\u001b[39m\u001b[38;5;124m'\u001b[39m], inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m data\n\u001b[1;32m---> 41\u001b[0m CA_interpolated_df \u001b[38;5;241m=\u001b[39m \u001b[43mcubic_spline_interpolate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCA_stations\u001b[49m\u001b[43m,\u001b[49m\u001b[43mgap_hours\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m24\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[39], line 34\u001b[0m, in \u001b[0;36mcubic_spline_interpolate\u001b[1;34m(data, gap_hours)\u001b[0m\n\u001b[0;32m     31\u001b[0m             cs \u001b[38;5;241m=\u001b[39m CubicSpline(x[mask], y[mask])\n\u001b[0;32m     32\u001b[0m             interpolated_data\u001b[38;5;241m.\u001b[39miloc[gap] \u001b[38;5;241m=\u001b[39m cs(gap)\n\u001b[1;32m---> 34\u001b[0m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtemperature\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcombine_first\u001b[49m\u001b[43m(\u001b[49m\u001b[43minterpolated_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     35\u001b[0m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtemperature\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtemperature\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mround(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     36\u001b[0m data\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)  \u001b[38;5;66;03m# Ensure the index is not dropped\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\lizbe\\Documents\\GitHub\\PHIT-Project-1\\.venv\\Lib\\site-packages\\pandas\\core\\series.py:3338\u001b[0m, in \u001b[0;36mSeries.combine_first\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m   3294\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   3295\u001b[0m \u001b[38;5;124;03mUpdate null elements with value in the same location in 'other'.\u001b[39;00m\n\u001b[0;32m   3296\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3335\u001b[0m \u001b[38;5;124;03mdtype: float64\u001b[39;00m\n\u001b[0;32m   3336\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   3337\u001b[0m new_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39munion(other\u001b[38;5;241m.\u001b[39mindex)\n\u001b[1;32m-> 3338\u001b[0m this \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreindex\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m   3339\u001b[0m other \u001b[38;5;241m=\u001b[39m other\u001b[38;5;241m.\u001b[39mreindex(new_index, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   3340\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m this\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mM\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m other\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mM\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\lizbe\\Documents\\GitHub\\PHIT-Project-1\\.venv\\Lib\\site-packages\\pandas\\core\\series.py:4918\u001b[0m, in \u001b[0;36mSeries.reindex\u001b[1;34m(self, index, axis, method, copy, level, fill_value, limit, tolerance)\u001b[0m\n\u001b[0;32m   4901\u001b[0m \u001b[38;5;129m@doc\u001b[39m(\n\u001b[0;32m   4902\u001b[0m     NDFrame\u001b[38;5;241m.\u001b[39mreindex,  \u001b[38;5;66;03m# type: ignore[has-type]\u001b[39;00m\n\u001b[0;32m   4903\u001b[0m     klass\u001b[38;5;241m=\u001b[39m_shared_doc_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mklass\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4916\u001b[0m     tolerance\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   4917\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Series:\n\u001b[1;32m-> 4918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreindex\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   4919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4920\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4922\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4923\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4924\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4925\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtolerance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtolerance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4926\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\lizbe\\Documents\\GitHub\\PHIT-Project-1\\.venv\\Lib\\site-packages\\pandas\\core\\generic.py:5360\u001b[0m, in \u001b[0;36mNDFrame.reindex\u001b[1;34m(self, labels, index, columns, axis, method, copy, level, fill_value, limit, tolerance)\u001b[0m\n\u001b[0;32m   5357\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_multi(axes, copy, fill_value)\n\u001b[0;32m   5359\u001b[0m \u001b[38;5;66;03m# perform the reindex on the axes\u001b[39;00m\n\u001b[1;32m-> 5360\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reindex_axes\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   5361\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtolerance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\n\u001b[0;32m   5362\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreindex\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\lizbe\\Documents\\GitHub\\PHIT-Project-1\\.venv\\Lib\\site-packages\\pandas\\core\\generic.py:5375\u001b[0m, in \u001b[0;36mNDFrame._reindex_axes\u001b[1;34m(self, axes, level, limit, tolerance, method, fill_value, copy)\u001b[0m\n\u001b[0;32m   5372\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   5374\u001b[0m ax \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_axis(a)\n\u001b[1;32m-> 5375\u001b[0m new_index, indexer \u001b[38;5;241m=\u001b[39m \u001b[43max\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreindex\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   5376\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtolerance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtolerance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\n\u001b[0;32m   5377\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   5379\u001b[0m axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_axis_number(a)\n\u001b[0;32m   5380\u001b[0m obj \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_reindex_with_indexers(\n\u001b[0;32m   5381\u001b[0m     {axis: [new_index, indexer]},\n\u001b[0;32m   5382\u001b[0m     fill_value\u001b[38;5;241m=\u001b[39mfill_value,\n\u001b[0;32m   5383\u001b[0m     copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[0;32m   5384\u001b[0m     allow_dups\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   5385\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\lizbe\\Documents\\GitHub\\PHIT-Project-1\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:4275\u001b[0m, in \u001b[0;36mIndex.reindex\u001b[1;34m(self, target, method, level, limit, tolerance)\u001b[0m\n\u001b[0;32m   4272\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot handle a non-unique multi-index!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   4273\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_unique:\n\u001b[0;32m   4274\u001b[0m     \u001b[38;5;66;03m# GH#42568\u001b[39;00m\n\u001b[1;32m-> 4275\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot reindex on an axis with duplicate labels\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   4276\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   4277\u001b[0m     indexer, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_indexer_non_unique(target)\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reindex on an axis with duplicate labels"
     ]
    }
   ],
   "source": [
    "def cubic_spline_interpolate(data, gap_hours=24):\n",
    "\n",
    "    data = data.copy()\n",
    "    data['temperature'] = pd.to_numeric(data['temperature'], errors='coerce')\n",
    "\n",
    "    # Convert to Datetime and set as index\n",
    "    data['Datetime'] = pd.to_datetime(data[['Year', 'Month', 'Day', 'Hour']])\n",
    "    data.set_index('Datetime', inplace=True)\n",
    "    data.sort_index(inplace=True)\n",
    "\n",
    "    # Resample to hourly data\n",
    "    hourly_data = data['temperature'].resample('h').mean()\n",
    "    is_missing = hourly_data.isna()\n",
    "\n",
    "    missing_indices = np.where(is_missing)[0]\n",
    "    gaps = np.split(missing_indices, np.where(np.diff(missing_indices) != 1)[0] + 1)\n",
    "\n",
    "    interpolated_data = hourly_data.copy()\n",
    "\n",
    "    for gap in gaps:\n",
    "        if len(gap) >= gap_hours:\n",
    "            start_index = max(gap[0] - 1, 0)\n",
    "            end_index = min(gap[-1] + 1, len(hourly_data) - 1)\n",
    "\n",
    "            x = np.arange(start_index, end_index + 1)\n",
    "            y = hourly_data.iloc[start_index:end_index + 1].values\n",
    "            mask = ~np.isnan(y)\n",
    "\n",
    "            if np.sum(mask) > 1:\n",
    "                # Apply cubic spline interpolation\n",
    "                cs = CubicSpline(x[mask], y[mask])\n",
    "                interpolated_data.iloc[gap] = cs(gap)\n",
    "\n",
    "    data['temperature'] = data['temperature'].combine_first(interpolated_data)\n",
    "    data['temperature'] = data['temperature'].round(1)\n",
    "    data.reset_index(drop=True, inplace=True)  # Ensure the index is not dropped\n",
    "    data.sort_values(by=['Station_ID', 'Year', 'Month', 'Day', 'Hour'], inplace=True)\n",
    "\n",
    "    return data\n",
    "\n",
    "CA_interpolated_df = cubic_spline_interpolate(CA_stations,gap_hours=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Station_ID</th>\n",
       "      <th>Station_name</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>temperature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Station_ID Station_name  Year  Month  Day  Hour  Latitude  Longitude  \\\n",
       "0        NaN          NaN   NaN    NaN  NaN   NaN       NaN        NaN   \n",
       "1        NaN          NaN   NaN    NaN  NaN   NaN       NaN        NaN   \n",
       "2        NaN          NaN   NaN    NaN  NaN   NaN       NaN        NaN   \n",
       "\n",
       "   temperature  \n",
       "0          NaN  \n",
       "1          NaN  \n",
       "2          NaN  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CA_interpolated_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of null values for each column: \n",
      "Station_ID      100.0\n",
      "Station_name    100.0\n",
      "Year            100.0\n",
      "Month           100.0\n",
      "Day             100.0\n",
      "Hour            100.0\n",
      "Latitude        100.0\n",
      "Longitude       100.0\n",
      "temperature     100.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "null_count = CA_interpolated_df.isna().sum()\n",
    "null_percent = (null_count/CA_interpolated_df.shape[0]) * 100\n",
    "print(f'Percentage of null values for each column: \\n{null_percent}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing Temperature Values: Handling short gaps in temperature observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a \"short gap\" as being a gap in the temperature column that is less than a day. \n",
    "\n",
    "Short gaps in temperature observations will be handled with forward/backward fill."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = fill_gaps(CA_interpolated_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_count = final_df.isna().sum()\n",
    "null_percent = (null_count/final_df.shape[0]) * 100\n",
    "print(f'Percentage of null values for each column: \\n{null_percent}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# make copies to not alter original dataframes\n",
    "plot_CA_stations = CA_stations.copy()\n",
    "plot_CA_interpolated = CA_interpolated_df.copy()\n",
    "\n",
    "plot_CA_stations['Datetime'] = pd.to_datetime(plot_CA_stations[['Year', 'Month', 'Day', 'Hour']])\n",
    "plot_CA_interpolated['Datetime'] = pd.to_datetime(plot_CA_interpolated[['Year', 'Month', 'Day', 'Hour']])\n",
    "\n",
    "plot_CA_stations.set_index('Datetime', inplace=True)\n",
    "plot_CA_interpolated.set_index('Datetime', inplace=True)\n",
    "\n",
    "monthly_avg_original = plot_CA_stations['temperature'].resample('ME').mean()\n",
    "monthly_avg_interpolated = plot_CA_interpolated['temperature'].resample('ME').mean()\n",
    "\n",
    "plt.figure(figsize=(14, 7))\n",
    "\n",
    "plt.plot(monthly_avg_original.index, monthly_avg_original.values, 'o-', label='Original Data', markersize=4)\n",
    "\n",
    "plt.plot(monthly_avg_interpolated.index, monthly_avg_interpolated.values, 'x-', label='Interpolated Data', markersize=4)\n",
    "\n",
    "plt.xlabel('Datetime')\n",
    "plt.ylabel('Temperature (¬∞C)')\n",
    "plt.title('Monthly Average Temperature (2003-2023)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outliers can skew our statistical analysis of the data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Visual Inspection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Boxplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.boxplot(x='Year', y='temperature', data=CA_interpolated_df)\n",
    "plt.title('Temperature Boxplot by Year')\n",
    "plt.xticks(rotation=90)  \n",
    "plt.ylabel('Temperature')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Statistical Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Z-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "# z_stations dataframe will have a Z_score column added to it\n",
    "z_stations = CA_interpolated_df.copy()\n",
    "z_stations['Z_score'] = stats.zscore(z_stations['temperature'])\n",
    "z_thresh = 3\n",
    "\n",
    "# calculate outliers using Z-score\n",
    "z_outliers = z_stations[(z_stations['Z_score'] < -z_thresh) | (z_stations['Z_score'] > z_thresh)]\n",
    "total_observations = z_stations.shape[0]\n",
    "\n",
    "num_outliers = z_outliers.shape[0]\n",
    "\n",
    "percent_outliers = (num_outliers / total_observations) * 100\n",
    "\n",
    "print(f'{percent_outliers:.2f}% of the observations are outliers')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Drop Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_stations_cleaned = z_stations[~((z_stations['Z_score'] < -z_thresh) | (z_stations['Z_score'] > z_thresh))]\n",
    "\n",
    "# Drop the Z_score column as it's no longer needed\n",
    "z_stations_cleaned = z_stations_cleaned.drop(columns=['Z_score'])\n",
    "\n",
    "# The z_stations_cleaned dataframe now contains the data without the outliers\n",
    "z_stations_cleaned.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UTC to Local Time Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_stations_cleaned['Datetime'] = pd.to_datetime(z_stations_cleaned[['Year', 'Month', 'Day', 'Hour']])\n",
    "z_stations_cleaned = z_stations_cleaned.drop(columns=['Year', 'Month', 'Day', 'Hour'])\n",
    "\n",
    "z_stations_cleaned['Datetime_local'] = z_stations_cleaned['Datetime'].dt.tz_localize('UTC').dt.tz_convert('US/Pacific')\n",
    "z_stations_cleaned['Year'] = z_stations_cleaned['Datetime_local'].dt.year\n",
    "z_stations_cleaned['Month'] = z_stations_cleaned['Datetime_local'].dt.month\n",
    "z_stations_cleaned['Day'] = z_stations_cleaned['Datetime_local'].dt.day\n",
    "z_stations_cleaned['Hour'] = z_stations_cleaned['Datetime_local'].dt.hour\n",
    "z_stations_cleaned = z_stations_cleaned.drop(columns=['Datetime', 'Datetime_local'])\n",
    "\n",
    "# remove 2002 observations\n",
    "z_stations_cleaned = z_stations_cleaned[z_stations_cleaned['Year'] != 2002]\n",
    "\n",
    "# rearrange columns\n",
    "cols = ['Station_ID','Station_name', 'Latitude', 'Longitude','Year','Month','Day','Hour','temperature']\n",
    "z_stations_cleaned = z_stations_cleaned[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_stations_cleaned.head()   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write dataframe to csv files by year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder = '../data/processed/ghcn_clean'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "years = z_stations_cleaned['Year'].unique()\n",
    "\n",
    "# Capitalize the temperature column to match the rest.\n",
    "z_stations_cleaned = z_stations_cleaned.rename(columns={'temperature': 'Temperature'})\n",
    "z_stations_cleaned.sort_values(by=['Station_ID', 'Year', 'Month', 'Day', 'Hour'], inplace=True)\n",
    "\n",
    "for year in years:\n",
    "    yearly_data = z_stations_cleaned[z_stations_cleaned['Year'] == year]\n",
    "    output_file = os.path.join(output_folder, f'CA_{year}_clean.csv')\n",
    "    yearly_data.to_csv(output_file, index=False)\n",
    "\n",
    "print('New datafrane yearly files saved to ghcn_cleaned')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
